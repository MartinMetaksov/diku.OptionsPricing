\chapter{Data generation}
\label{chapter:datageneration}
Until this point, all implementations have been tested and validated on examples from the book (book.in and options-60000.in). Doing this helps determine the correctness of the implementations and gives some hints about the running times of each version, however neither of the data sets can be used to infer meaningful conclusions for the implementations. While book.in is too small, options-60000.in has an uniform distribution, where a single option is replicated 60000 times. To challenge the implementations we have created a simple data set generator, which works with several different distributions. This chapter will introduce the reader to the data set generator and the sets that were generated to put the implementations to test and help discover performance differences.   

\section{Generator overview}
The generator was implemented in C++ and takes 3 arguments as input - total number of options in the set, a skewness parameter and the data distribution type to be generated. The inputted number of options is used as a max limit when generating options. All of the generated sets described in this chapter have been created with $2^16=65536$ options, which is double of the total number of available threads on the GPU that was used for this thesis (32768). The skewness parameter represents the amount (in percent) of options that will be skewed (have significantly different height and/or width than the rest of the file). This parameter is applied only for the skewed distributions, which will be described later in this chapter. Last but not least, the data distribution type is used to specify the data set which will be generated. The generator currently works with 6 different sets, which will be described next in this report. 

\section{Uniform}
The uniform data set consists of the same option replicated multiple times. Each entry in this set has the same height and the same width as the others. Note that options-60000.in has the same distribution, however it provides no guarantee that the number of computations needed to process it will be the same as the one required to process the other data sets described further in this chapter. For this reason, a new uniformly distributed set is created, which should meet these prerequisites. All widths in the set we have generated are equal to 47 and all heights to 109. As this set is uniformly distributed, all other statistics such as variance, std, skewness are 0 for both widths and heights. The data distribution is shown on fig. \ref{fig:data:uniform}\footnote{Note that this and the following data distribution plots consist of a scatter plot where each dot represents an option, and histogram plots next to their corresponding axis, indicating on the data distribution}, where it can be seen that a dot is formed in the center of the plot. While pricing the same option this many times is not practically/financially useful, there is a possibility that many real-life inputs will have a uniform distribution, where both their widths and heights will have close values. In such a case, the dots on the plot will be separated, but will still remain close to the center. This implies that in these distributions, pricing individual options will also take similar times. In our generated data set, each option should be priced in exactly the same amount of time. Furthermore, since there is no difference in the heights and the widths, it is not expected that pricing this data distribution in parallel will benefit from any sorting or padding.   
 
 \begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{img/0_UNIFORM_plot.png}
	\caption{Data distribution for 0\_Uniform.in.}
    \source{Compiled by the authors}
	\label{fig:data:uniform}
\end{figure}

\section{Random}
The random data set consists of options with both uniformly distributed random widths and uniformly distributed random heights. This data set is interesting, as it presents a wide variety of option sizes. Both padding and sorting can benefit the processing of such a data distribution, hence the data set can help answer questions concerned with the various optimization techniques that can possibly improve the performance of the algorithm. The random data set we have generated has the following statistics:

widths: min 7, max 511, mean 259.78, variance 21293.52, std 145.92, skewness -0.01, kurthosis -1.20.

heights: min 13, max 1201, mean 606.26, variance 120065.68, std 346.50, skewness 0.00, kurthosis -1.20.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{img/1_RAND_plot.png}
	\caption{Data distribution for 1\_Rand.in.}
	\source{Compiled by the authors}
	\label{fig:data:random}
\end{figure}

\section{Random with constant height/width}
The following two data sets (see fig. \ref{fig:data:randconstheight} and fig. \ref{fig:data:randconstwidth}) have a similar structures to the random one described above, however one of their parameters is being held in place (constant). In the case of constant height, the width is uniformly random distributed, while the height remains the same throughout all options. The other set is vice verse, where the width remains the same, while the height is randomly distributed. These data sets should help strengthen the importance of sorting and padding and the performance improvements they can introduce. The two data sets we have generated have the following statistics:

For set 2 with constant height equal to 109:
widths: min 7, max 511, mean 258.52, variance 21358.88, std 146.15,
skewness -0.00, kurthosis -1.20.

For set 3 with constant width equal to 47: 
heights: min 13, max 1201, mean 607.04, variance 119714.09, std 346.00, skewness -0.00, kurthosis -1.20.

\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{img/2_RANDCONSTHEIGHT_plot.png}
  \caption{Constant height}
  \label{fig:data:randconstheight}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{img/3_RANDCONSTWIDTH_plot.png}
  \caption{Constant width}
  \label{fig:data:randconstwidth}
\end{subfigure}
\caption{Data distributions for 2\_Randconstheight.in (a) and 3\_Randconstwidth.in.}
\label{fig:test}
\source{Compiled by the authors}
\end{figure}

\section{Skewed}
This data set introduces data skewness, where a small percent of all options is significantly different than the rest. As it can be seen in fig. \ref{fig:data:skewed} the majority of the data has widths up to approx. 100 and heights up to approx. 1200. Several options with much larger heights and widths stand out with much larger range for both widths and heights. This data distribution can also often occur in real life situations, where several data entries significantly deviate from the rest. This introduces problems with memory padding in some of the implementations, but can benefit from sorting both along the height and along the width. It is further interesting to observe whether cuda-multi can produce any performance increase on data sets where the majority of options have small widths, hence allowing to pack and process several options in parallel. The data set we have generated has the following statistics: 

widths: min 7, max 511, mean 60.90, variance 2490.82, std 49.91, skewness 5.19, kurthosis 40.29.

heights: min 13, max 1201, mean 195.35, variance 17598.95, std 132.66, skewness 2.40, kurthosis 14.07.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{img/4_SKEWED_plot.png}
	\caption{Data distribution for 4\_Skewed.in.}
	\source{Compiled by the authors}
	\label{fig:data:skewed}
\end{figure}

\section{Skewed with constant height/width}
The last two data sets (see fig. \ref{fig:data:skewedconstheight} and fig. \ref{fig:data:skewedconstwidth}) introduce similar concepts as the random constant height/width data sets. Here the majority of the data has a uniform random distribution on both axes, however one of the axes creates a limit - max value. E.g. in the skewed with constant height data set, the width is limited to approximately 50, while the height can take any number up to approx 1200. The skewed part of this data set has a constant height, which does not stand out from the other options, differently from the width, which varies in a much larger spectrum - between approx. 410 and 510. This is vice verse on the other set - skewed with constant width, where the majority of options consists of options with varying width, but low heights and a skewed part, consisting of a small fixed width and heights within a larger spectrum. The purpose of these sets is an attempt to distinguish the impact of skewed large widths or skewed large heights can have on the implementations and strengthen the performance increase hypotheses when sorting and padding is performed. The two data sets we have generated have the following statistics:

For set 5 with constant width of the skewed part where height is equal to approx. 120:
widths: min 7, max 511, mean 61.06, variance 2493.88, std 49.94,
skewness 5.15, kurthosis 39.87.

heights: min 13, max 1201, mean 602.58, variance 121471.29, std 348.53, skewness 0.01, kurthosis -1.22.

For set 6 with constant height of the skewed part where width is equal to 47:
widths: min 7, max 507, mean 254.24, variance 21164.27, std 145.48, skewness 0.02, kurthosis -1.21.

heights: min 13, max 1201, mean 194.23, variance 17615.88, std 132.72, skewness 2.41, kurthosis 14.05.

\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{img/5_SKEWEDCONSTHEIGHT_plot.png}
  \caption{Constant height}
  \label{fig:data:skewedconstheight}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{img/6_SKEWEDCONSTWIDTH_plot.png}
  \caption{Constant width}
  \label{fig:data:skewedconstwidth}
\end{subfigure}
\caption{Data distributions for 5\_Skewedconstheight.in (a) and 6\_Skewedconstwidth.in.}
\source{Compiled by the authors}
\end{figure}

% \section{Other data used}
% - shall we write a bit about Wojciechs data ?

\section*{Summary}
This chapter has introduced the reader to the different data sets that have been generated to support the thesis. While not all of them seem realistic in practise, their purpose is to cover edge cases, which can occur seldomly in real-life scenarios. Using these sets can help discover possible bugs in the implementations, as well as highlight on the performance difference between the versions and parallelism used to process data. The data sets will be used in order to obtain running times and create benchmarks for the algorithm and the different implementations with their versions. Benchmarking will be described in the next chapter - \ref{chapter:benchmarking}.
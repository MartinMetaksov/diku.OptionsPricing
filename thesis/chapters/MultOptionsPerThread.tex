\chapter{Multiple Options per Thread Block}
\label{chapter:multoptionsperthreadblock}
This chapter describes our CUDA implementation that prices multiple options in one thread block. This approach exploits inner parallelism, leveraging fast shared memory for computations of $\mathit{Qs}$ and $\mathit{Prices}$. The limitation of this version is that it cannot price options with widths bigger than the size of a thread block (1024), since every thread computes one value along the tree width. The flattening transformations applied to derive a multiple options per thread block implementations and the ones used to derive a fully flattened implementation are semantically the same, as it will be shown later in section~\ref{chapter:section:multiflatdifference}. For this reason, we have explained them in thorough details in the context of a functional language in chapter~\ref{chapter:fullflattening}, making them easier to understand. Instead, the descriptions in this chapter are more focused on CUDA-specific challenges.

\section{CUDA-option to CUDA-multi}
To implement this parallel approach, we used CUDA-option as a basis, reusing code that is not specific to each version, such as parts of pre-processing and some computations.

\subsection{Memory setup}
In this implementation one thread does not compute the whole tree for an option, rather it computes a single value on the tree width. This allows us to move the array of $\mathit{Qs}$ to shared memory and even remove the array of $\mathit{QsCopy}$, as it was used to hold $\mathit{Qs}$ temporarily between computations, and now a single $Q$ value can be temporarily stored in a thread register. Shared memory thus comprises of one real array of $\mathit{Qs}$ and one $uint16\_t$ array of $\mathit{flags}$ (used by segmented scans), both of thread block size. Global memory then stores all the options along with their pre-computed widths and heights, and the array of all $\mathit{alphas}$.

\subsection{Pre-processing}
\label{section:cudamulti:preprocessing}
After the options are loaded to GPU memory and their widths and heights are computed, they have to be split into chunks. A chunk represents one or more options whose combined widths can fit into the chosen thread block size. This process is also known as bin packing, which is a combinatorial NP-hard problem, so we decided to implement it in a simple way on the CPU, since it is not a focus of this thesis. The options are packed by a for-loop, in which an option is put into the current chunk if the sum of width sizes for options stored already in the chunk does not exceed the thread block size, otherwise a new chunk is created and the current option index is added to an array of indices. This produces an array of option indices, e.g. $[1, 3, 5]$, which describes that there are 5 options computed by 3 thread blocks, the first block will compute option 0, the second one options 1 and 2, and the third one options 3 and 4.

It is obvious that this simple implementation packs options into a smaller number of chunks/blocks if the options are sorted by width. However, it should also be desirable to sort the options by height to optimize thread divergence, since computations on the tree width are parallelized. Therefore, a better bin packing implementation might improve performance by packing more options into chunks by their widths, while optimizing thread divergence on heights, probably as a trade-off for more pre-processing time.

\subsection{Flattening}
Algorithm~\ref{alg:cuda-multi}-\ref{alg:cuda-multi-backward} outlines the kernel written for this implementation, which is much more complex than the kernel that computes one option per thread described in chapter~\ref{chapter:oneoptionperthread}. Since computed values are dependent on results from multiple threads, it is important to synchronize threads in the block to prevent race conditions. However, special care has to be taken for this not to result in deadlocks because of thread divergence, caused by options with different widths and heights inside a block. 

\paragraph{Initialization}
First, option indices $\mathit{inds}$ for a block have to be distributed to threads based on option widths, such that each thread can compute one value in $\mathit{Qs}$. For example, threads 0-200 compute option 0 with width 201 and threads 201-1000 compute option 1 with width 799, leaving threads 1001-1023 unoccupied. This is done by a series of segmented scans on arrays with indices and widths, resulting in every thread in block getting an index of the option to compute ($\mathit{optionIdx}$) and $\mathit{scannedWidthIdx}$ representing the start index of $\mathit{Qs}$ (Alg.~\ref{alg:cuda-multi},~\ref{alg:cuda-multi2},~\ref{alg:cuda-multi3} lines 10-65). Afterwards, one thread per option initalizes the first $Q$ and $\mathit{alpha}$ value (Alg.~\ref{alg:cuda-multi3} lines 69-71). To access the global array of $\mathit{alphas}$, a thread uses helper functions \emph{getAlphaAt(index, optionIndex)} and \emph{setAlphaAt(index, value, optionIndex)} that compute global array indices based on the specific version described later in section~\ref{section:cuda-multi-versions}. It can be noted that the actions performed in the initialization have close resemblance to some of the transformations described in chapter \ref{chapter:section:flattening}. However, it is difficult to relate them to a single specific flattening transformation (e.g. $map$, $reduce$, $replicate$), as CUDA is not using any of those functions directly.

\paragraph{Forward propagation}
In the loop, it is important that all threads use the maximum height of options in the block, not the height of their option which might be smaller. This way block-level synchronization can be used inside the loop without the possibility of deadlocks. However, at each time step a thread has to check if it should even compute new $\mathit{Qs}$ based on its option's height. First, a thread pre-computes the next $Q$ value, then all threads can quickly compute the next $Q$ value from multiple $\mathit{Qs}$ in the previous step and save it in a local variable (Alg.~\ref{alg:cuda-multi-forward} lines 75-88). Afterwards, $\mathit{Qs}$ are multiplied in order to be summed up using parallel segmented scan (Alg.~\ref{alg:cuda-multi-forward} lines 90-92). Next, a new alpha value is computed from the last scanned $Qs$ per option (Alg.~\ref{alg:cuda-multi-forward} lines 95-98). Lastly, all threads set $\mathit{Qs}$ to the new $Q$ values (Alg.~\ref{alg:cuda-multi-forward} line 99).

\paragraph{Backward propagation}
Before the loop, each threads sets $\mathit{Qs}$ to 100 (called $\mathit{Prices}$ in the sequential implementation, reusing the array in this version) (Alg.~\ref{alg:cuda-multi-backward} lines 103-104). Then in the loop, threads have to use max height again in order to use thread synchronization. Each thread computes one price in the previous time step (if valid for current option) and after all of them are done, they store the values and move to another step (Alg.~\ref{alg:cuda-multi-backward} lines 106-119). After the whole tree is traversed, one thread per option sets the price result in the global results array (Alg.~\ref{alg:cuda-multi-backward} lines 122-124).

\newpage
\begin{algorithm}[H]
\DontPrintSemicolon
\caption{Multiple options per thread block kernel\label{alg:cuda-multi}}
\SetKw{And}{and}
\SetKw{Scan}{scanPlus}
\SetKw{Syncthreads}{\_\_syncthreads}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}

\underline{function kernelMultipleOptionsPerBlock}\;
\Input{options : \{ [StrikePrices], [Maturities], [Lengths], [TermUnits], [TermStepCounts], [ReversionRates], [Volatilities], [Types], [Widths], [Heights] \},\\ yields : \{ [Prices], [Timesteps] \}\\ [inds], [alphas], [results]}
\Output{Price approximations for the options in block}
\;
\tcc{Initialize shared memory references}
volatile extern \_\_shared\_\_ char sh\_mem[]\tcc*{Memory array for block}
Qs = (real *)\&sh\_mem\tcc*{Qs are the first part}
values = (int32\_t *)\&sh\_mem\tcc*{Helper int array, overwrites Qs}
flags = (uint16\_t *)\&sh\_mem[$\text{blockDim.x} * \text{sizeof(real)}$]\tcc*{After Qs}
\;
\tcc{Compute option indices and scanned widths}
idxBlock = blockIdx.x == 0 ? 0 : inds[$\text{blockIdx.x} - 1$]\;
idxBlockNext = inds[blockIdx.x]\;
idx = $\text{idxBlock} + \text{threadIdx.x}$\;
width = 0\; 
\eIf(\tcc*[f]{Don't fetch options from next block}){$\mathit{idx} < \mathit{idxBlockNext}$}
{
    width = options.Widths[idx]\;
    values[threadIdx.x] = width\;
}
{
    values[threadIdx.x] = 0\;
}
\Syncthreads\;
\end{algorithm}

\newpage
\begin{algorithm}[H]
\DontPrintSemicolon
\setcounter{AlgoLine}{20}
\caption{Multiple options per thread block kernel - cont. 2\label{alg:cuda-multi2}}
\SetKw{And}{and}
\SetKw{Scan}{scanPlus}
\SetKw{Sgmscan}{sgmScanPlus}
\SetKw{Syncthreads}{\_\_syncthreads}

\tcc{Scan widths inplace to obtain indices to Qs for each option}
\Scan{values}\;
$\text{scannedWidthIdx} = -1$\;
\If{$\mathit{idx} <= \mathit{idxBlockNext}$}
{
    \tcc{Get the scanned width as in exclusive scan}
    scannedWidthIdx = threadIdx.x == 0 ? 0 : values[$\text{threadIdx.x} - 1$]\;
}
\Syncthreads\;
\;
\tcc{Send option indices to all threads}
values[threadIdx.x] = 0\tcc*{Clear values and flags}
flags[threadIdx.x] = 0\;
\Syncthreads\;
\;
\tcc{Set values to option indices and flags to option widths}
\uIf{$\mathit{idx} < \mathit{idxBlockNext}$}
{
    values[scannedWidthIdx] = threadIdx.x\;
    flags[scannedWidthIdx] = width\;
}
\ElseIf{$\mathit{idx} == \mathit{idxBlockNext}$ \And $\mathit{scannedWidthIdx} < \mathit{blockDim.x}$}
{
    \tcc{Fill the remaining part of the block (if any)}
    values[scannedWidthIdx] = threadIdx.x\;
    flags[scannedWidthIdx] = $\text{blockDim.x} - \text{scannedWidthIdx}$\;
}
\Syncthreads\;
\;
\tcc{Scan option indices with widths as flags to distribute them}
\Sgmscan{values flags}\;
optionIdxBlock = values[threadIdx.x]\tcc*{Option index within block}
\end{algorithm}

\newpage
\begin{algorithm}[H]
\DontPrintSemicolon
\setcounter{AlgoLine}{48}
\caption{Multiple options per thread block kernel - cont. 3\label{alg:cuda-multi3}}
\SetKw{And}{and}
\SetKw{Scan}{scanPlus}
\SetKw{Sgmscan}{sgmScanPlus}
\SetKw{Syncthreads}{\_\_syncthreads}

\tcc{Let all threads know about their scannedWidthIdx (Q start)}
\If{$\mathit{idx} <= \mathit{idxBlockNext}$}
{
    flags[threadIdx.x] = scannedWidthIdx\;
}
\Syncthreads\;
scannedWidthIdx = flags[optionIdxBlock]\;
\;
\tcc{Get the option for thread and compute its constants}
OptionConstants c\;
optionIdx = idxBlock + optionIdxBlock\;
\eIf{$\mathit{optionIdx} < \mathit{idxBlockNext}$}
{
    c = Compute constants for options[optionIdx]\;
}
(\tcc*[f]{Fake option to fill block})
{
    c.n = 0\;
    c.width = $\text{blockDim.x} - \text{scannedWidthIdx}$\;
}
\Syncthreads\;
\;
\tcc{Initialize Qs and alphas in one thread per option}
\If{$\mathit{threadIdx.x} == \mathit{scannedWidthIdx}$ \And $\mathit{optionIdx} < \mathit{idxBlockNext}$}{
    alpha = compute yield at dt\tcc*{Initial alpha value}
    setAlphaAt(0, alpha, optionIdx)\;
    Qs[scannedWidthIdx + jmax] = 1\tcc*{Initial Q value}
}
\end{algorithm}

\newpage
\begin{algorithm}[H]
\DontPrintSemicolon
\setcounter{AlgoLine}{72}
\caption{Multiple options per thread block kernel - cont. 4\label{alg:cuda-multi-forward}}
\SetKw{And}{and}
\SetKw{Sgmscan}{sgmScanPlus}
\SetKw{Syncthreads}{\_\_syncthreads}

\tcc{Forward propagation}
\For{$i = 1$ \KwTo maxHeight}{
    jhigh = min(i, c.jmax)\;
    j = $\text{threadIdx.x} - \text{c.jmax} - \text{scannedWidthIdx}$\;
    \tcc{If both height and width steps are valid for this option}
    \If{$i <= \mathit{c.height}$ \And $j >= -\mathit{jhigh}$ \And $j <= \mathit{jhigh}$}{
        alpha = getAlphaAt($\text{i} - 1$, threadIdx.x)\;
        Qs[threadIdx.x] *= exp(...)\tcc*{Pre-compute Qs using alpha}
    }
    \Syncthreads\;
    \;
    Q = 0\;
    \If{$i <= \mathit{c.height}$ \And $j >= -\mathit{jhigh}$ \And $j <= \mathit{jhigh}$}{
        Q = Compute next step from Qs
    }
    \Syncthreads\;
    \;
    Qs[threadIdx.x] = $\text{Q} * \text{exp(...)}$\tcc*{Set Qs for summation}
    \Syncthreads\;
    \Sgmscan{Qs flags}\tcc*{Sum up Qs}\;
    \tcc{Get last values of segmented scans (reduced results)}
    \If{$i <= \mathit{c.height}$ \And $\mathit{threadIdx.x} == \mathit{scannedWidthIdx} + \mathit{c.width} - 1$}{
        alpha = Compute alpha from Qs[threadIdx.x]\;
        setAlphaAt(i, alpha, optionIdx)
    }
    Qs[threadIdx.x] = Q\tcc*{Set Qs to new values}
    \Syncthreads\;
}
\end{algorithm}

\newpage
\begin{algorithm}[H]
\DontPrintSemicolon
\setcounter{AlgoLine}{101}
\caption{Multiple options per thread block kernel - cont. 5\label{alg:cuda-multi-backward}}
\SetKw{And}{and}
\SetKw{Syncthreads}{\_\_syncthreads}
\tcc{Backward propagation}
Qs[threadIdx.x] = 100\tcc*{Init prices to 100\textdollar}
\Syncthreads\;
\;
\For{$i = \mathit{maxHeight} - 1$ \KwTo 0}{
    jhigh = min(i, c.jmax)
    j = $\text{threadIdx.x} - \text{c.jmax} - \text{scannedWidthIdx}$\;
    price = Qs[threadIdx.x]\;
    \Syncthreads\;
    \;
    \If{$i <= \mathit{c.height}$ \And $j >= -jhigh$ \And $j <= \mathit{jhigh}$}{
        alpha = getAlphaAt($\text{i} - 1$, optionIdx)\;
        price = Compute new price using alpha
    }
    \Syncthreads\;
    \;
    Qs[threadIdx.x] = price\tcc*{Set prices to new values}
    \Syncthreads\;
}
\;
\tcc{Set results to prices on the first nodes}
\If{$\mathit{optionIdx} < \mathit{idxBlockNext}$ \And $\mathit{threadIdx.x} == \mathit{scannedWidthIdx}$}{
    results[optionIdx] = Qs[scannedWidthIdx + c.jmax]
}
\end{algorithm}
\newpage

\section{Implementations \& Validation}
\label{section:cuda-multi-versions}
We derived 3 implementations that differ only in the way how the array of $\mathit{alphas}$ in global memory is stored and accessed. It is similar to the 4 CUDA-option versions, except that the array of $\mathit{Qs}$ is not of concern here because it is in shared memory.

\subsection*{Version 1 - Naive}
The first simple version was created to be a starting point for the other versions and for comparison. The $\mathit{alphas}$ are padded on a global level, thus the size equals the maximum height of all options times the number of options. Values are accessed in a straightforward way as $\mathit{maxHeight} * \mathit{optionIndex} + \mathit{index}$. However, this access is not coalesced and the next two versions solve that to improve performance.

\subsection*{Version 2 - Global-level Padding with Coalescing}
The second version is similar, since the $\mathit{alphas}$ are padded on a global level. However, the values are being accessed in transposed form as $\mathit{optionsCount} * \mathit{index} + \mathit{optionIndex}$. This simple change in indexing should result in performance speed-ups for no additional cost, either in terms of storage requirements or pre-processing time. Interestingly, in our experiments, this version did not lead to noticeable performance gains, probably because \textit{alphas} are not accessed as often as \textit{Qs} which are already in shared memory, and version 1 does have global-level padding.

\subsection*{Version 3 - Block-level Padding}
The third version tries to improve on storage requirements as it uses padding for $\mathit{alphas}$ on block level. It does so by computing an array of indices to $\mathit{alphas}$, each value representing the beginning of a segment allocated for a single block. One segment is of size maximum height of options in the block times the number of options in the block. The values are then accessed in a slightly more complicated way as $\mathit{alphaIndexForBlock} + \mathit{optionIndexInBlock} + \mathit{optionsCountBlock} * \mathit{index}$. This should result in less global memory being allocated in trade-off for an array of indices created, and then accessed in the kernel. It might also lead to speed-ups due to improved locality of reference. For our datasets, this version performs up to \textasciitilde$3\times$ faster while using up to 6x less memory than versions 1 and 2. Note that warp-level padding is not possible to achieve in this approach as one option can be computed by multiple warps.

\subsection*{Optimizations}
\label{chapter:cudamulti:optimizations}
\paragraph{Choosing thread block size}
Due to the nature of this approach, it is best to choose the biggest thread block size available to be able to manually pack as many options into a block as possible. All versions when compiled use more than 64 registers which effectively limits the thread block size to 512. However, we can also limit the amount of registers\footnote{We can limit the number of registers by setting the \textit{nvcc} compiler flag \textit{--maxrregcount=32}, as mentioned in https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#options-for-steering-gpu-code-generation} in order to be able to use the maximum block size of 1024. During our experiments, we observed that limiting the number of registers to 32 and setting block size to 1024 gives the best performance (up to \textasciitilde$2.3\times$ faster) as it lead to full occupancy of the device SMs.

\paragraph{Sorting input}
This approach eliminates thread divergence caused by different option widths by applying flattening to the inner parallelism. In order to reduce thread divergence on heights, it should be beneficial to sort the options by height before computation. However, sorting options by width might lead to more efficient packing of options into chunks. Experiments show that sorting by height gives better performance for all tested datasets, up to \textasciitilde$2.3\times$ faster than no sorting.

\subsection*{Validation}
Computed results from all 3 versions are validated by expanding the test case described in section~\ref{section:option:validation}. Furthermore, chapter~\ref{chapter:experimentalresults} will describe tests using bigger datasets.

\section*{Summary}
This chapter provided an overview of our parallel multiple options per thread block implementation using CUDA with focus on explaining the challenges of exploiting the inner parallelism, compared to the one option per thread implementation from chapter~\ref{chapter:oneoptionperthread}. It introduced 3 versions of this parallel implementation, the final third version being the best performing one. Finally, it described how the GPU results were validated against the CPU results using our common CUDA test case. The following chapter will introduce the third parallel approach --- full flattening.